# Configuration for Long-LRM evaluation aligned with SparseSplat
# This config uses the same input/test views as SparseSplat for fair comparison

# Inherit from base config if needed
# You can specify this as --default-config when running main.py

checkpoint_dir: "checkpoints"
evaluation_dir: "eval_results"
use_tf32: true
use_amp: true
amp_dtype: "bf16"

data:
  # These will be overridden by data_eval below in evaluation mode
  data_path: "data/dl3dv_train.txt"
  resize_h: 256
  resize_w: 448
  square_crop: false
  patch_size: 8
  input_frame_select_type: "uniform"
  target_frame_select_type: "uniform"
  num_input_frames: 6
  num_target_frames: 50
  target_has_input: true
  min_frame_dist: "all"
  shuffle_input_prob: 0.0
  reverse_input_prob: 0.0
  random_crop: 1.0
  scene_scale: 1.0

# Evaluation-specific data configuration
data_eval:
  # Path to scene list file (generated by create_scene_list.py)
  data_path: "data/dl3dv_eval_scenes.txt"

  # Enable SparseSplat index alignment
  use_sparsesplat_index: true
  sparsesplat_index_path: "/data/zhangzicheng/workspace/SparseSplat-/SparseSplat/assets/dl3dv_start_0_distance_50_ctx_6v_video_0_50.json"

  # Resolution
  resize_h: 256
  resize_w: 448
  square_crop: false

  # Frame selection (ignored when use_sparsesplat_index=true, but kept for compatibility)
  input_frame_select_type: "fixed_indices"
  target_frame_select_type: "fixed_indices"
  num_input_frames: 6
  num_target_frames: 50
  target_has_input: true

  # No random augmentation in evaluation
  shuffle_input_prob: 0.0
  reverse_input_prob: 0.0
  random_crop: 1.0

model:
  patch_size: 8
  dim: [256, 1024]  # Feature dimensions (updated to match checkpoint)
  num_layers: 24
  block_type: "tmtmtmtmtmtmtmtmtmtmtmtm"  # Alternating transformer and mamba2
  merge_layers: [8]  # Merge at layer 8 (updated to match checkpoint)
  num_global_tokens: 2  # Updated to match checkpoint (was 128)

  transformer:
    head_dim: 64

  mamba2:
    d_state: 256  # Updated to match checkpoint (was 128)

  gaussians:
    sh_degree: 2
    max_dist: 10.0
    scale_bias: -3.0
    scale_max: 3.0
    opacity_bias: -1.5
    near_plane: 0.01
    far_plane: 1000.0
    prune_ratio: 0.5
    random_ratio: 0.1
    opacity_threshold: 0.001
    align_to_pixel: true

training:
  # Training parameters (not used in evaluation mode)
  lr: 0.0001
  batch_size_per_gpu: 1
  train_steps: 10000
  grad_accum_steps: 1
  num_workers: 4
  prefetch_factor: 2

  # Resume from pre-trained 32-input checkpoint
  resume_ckpt: "checkpoints/dl3dv_i540_32input_8target/checkpoint_000010000.pt"
  reset_training_state: true

  warmup_steps: 0
  weight_decay: 0.0
  beta1: 0.9
  beta2: 0.95
  grad_clip_norm: 1.0
  scheduler_type: "cosine"

  # Loss weights
  l2_loss: 1.0
  perceptual_loss: 0.0
  opacity_loss: 0.0
  gaussian_depth_loss: 0.0

  # Logging
  print_every: 10
  wandb_every: 100
  checkpoint_every: 1000
  vis_every: 100
  save_gaussian_every: 1000
  save_video_every: 1000
  wandb_offline: false
  wandb_entity: "your_entity"
  wandb_project: "longlrm"

# Path to API keys (for wandb)
api_key_path: "api_keys.yaml"

# Evaluation-specific settings
insert_frame_num: 8  # For input trajectory video interpolation
